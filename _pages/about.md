---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I'm a MSc student at S√£o Paulo State University (UNESP), also working with Deep Learning at the CK-12 Foundation, with focus on multimodal representation learning and Natural Language Processing.

Academic bio
======
My current research focuses on exploring Quantum Computing for biomedical applications, specifically on parkinsonian speech detection using Quantum Neural Networks, considering both classical and nonlinear features. I am very honored to be advised by , both of which have greatly helped me grow as a researcher.

More recently, I've been very interested on the mathematical foundations of Quantum Machine Learning, with focus on group-theoretic representation of geometric priors on quantum models. Other areas of interest for me are Graphs Neural Networks & Multimodal Representation Learning.

Before this, I graduated in 2019 as a Bachelor in Computer Science at UNESP, and in my dissertation I used [Paraconsistent Feature Engineering](https://ieeexplore.ieee.org/document/8588433) and Machine Learning for the development of a novel index for diagnosis of Keratoconus - both clinical and subclinical.

Awards
======
‚òÖ Deep Knowledge - Awarded for the contributions on Quantum Natural Language Processing - NTT Data

‚òÖ Meaningful Innovation - Participated in the foundation of the Quantum Computing initiative - NTT Data. 

üèÖ Gold medal - Brazilian Astronomy Olympiad - Brazilian Astronomy Olympiad 2015

ü•â Bronze medal - Brazilian Physics Olympiad - 2015

ü•â Bronze medal - Brazilian Physics Olympiad - 2014

ü•à Silver medal - Brazilian Astronomy Olympiad - 2014

üèÜ Selected to the final stage to represent the Brazilian Team in the International Olympiad of Astronomy and Astrophysics - 2015

GitHub projects
======
- [Quantum Sentence Transformer](https://github.com/jogisuda/QuantumSentenceTransformer): This project aims to shed light on Quantum Natural Language Processing. The model leverages parametrized circuits and [hybrid classical-quantum transfer learning](https://arxiv.org/abs/1912.08278) to come up with meaningful sentence representations. All code uses Pennylane and Sentence Transformers.
- [Discrete Path Transform](https://github.com/jogisuda/Discrete-Path-Transform): code for the DPT, developed jointly with the Signal Processing lab at UNESP.
- [ParaconsistentLIB](https://github.com/jogisuda/paraconsistentLIB) - paraconsistent logic-based feature engineering.
- [pyGAMESS-DS](https://github.com/jogisuda/pyGAMESS-DS) - automated retrieval of main molecular informations from GAMESS-US, like geometry-optimized coordinates, Gibbs energy corrections, net charges, etc.
